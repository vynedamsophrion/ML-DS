{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7260dba",
   "metadata": {},
   "source": [
    "# Simple Prompt Engineering Examples\n",
    "\n",
    "This notebook demonstrates three prompting techniques using a simple math problem."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "922a3380",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 2,
   "id": "922a3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
>>>>>>> recover-day2
   "source": [
    "# Setup\n",
    "!pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "9665bee6",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 3,
   "id": "9665bee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "WARNING:tensorflow:From c:\\python software\\python 3.12.3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python software\\python 3.12.3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
>>>>>>> recover-day2
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the model\n",
    "print(\"Loading model...\")\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "26fae57e",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 4,
   "id": "26fae57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will test this question: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n"
     ]
    }
   ],
>>>>>>> recover-day2
   "source": [
    "# Our test question\n",
    "question = \"A farmer has 17 sheep and all but 9 run away. How many sheep are left?\"\n",
    "print(f\"We will test this question: {question}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "813c3199",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 5,
   "id": "813c3199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing zero-shot prompting...\n",
      "\n",
      "ðŸ”¹ Zero-shot response:\n",
      "Question: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all\n",
      "\n",
      "ðŸ”¹ Zero-shot response:\n",
      "Question: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all but 9 run away. How many sheep are left?\n",
      "Answer: 17 sheep and all\n"
     ]
    }
   ],
>>>>>>> recover-day2
   "source": [
    "# 1. Zero-shot prompting\n",
    "print(\"Testing zero-shot prompting...\")\n",
    "zero_shot = generator(\n",
    "    f\"Question: {question}\\nAnswer:\", \n",
    "    max_length=50, \n",
    "    num_return_sequences=1\n",
    ")\n",
    "print(\"\\nðŸ”¹ Zero-shot response:\")\n",
    "print(zero_shot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "46aa3472",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 6,
   "id": "46aa3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing few-shot prompting...\n",
      "\n",
      "ðŸ”¹ Few-shot response:\n",
      "Here are some math problems:\n",
      "\n",
      "Q: There are 10 apples and you eat 4. How many are left?\n",
      "A: 6\n",
      "\n",
      "Q: You have 8 pencils and lose 3. How many do you have?\n",
      "A: 5\n",
      "\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: 6\n",
      "Q: If you have a few cows and have a few sheep, how many are left?\n",
      "A: 2\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 3\n",
      "Q: Do you have 9 cows and you eat 8. What else?\n",
      "A: 5\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you\n",
      "\n",
      "ðŸ”¹ Few-shot response:\n",
      "Here are some math problems:\n",
      "\n",
      "Q: There are 10 apples and you eat 4. How many are left?\n",
      "A: 6\n",
      "\n",
      "Q: You have 8 pencils and lose 3. How many do you have?\n",
      "A: 5\n",
      "\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: 6\n",
      "Q: If you have a few cows and have a few sheep, how many are left?\n",
      "A: 2\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 3\n",
      "Q: Do you have 9 cows and you eat 8. What else?\n",
      "A: 5\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. Do you have more cows?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you eat 8. What else?\n",
      "A: 6\n",
      "Q: You have 10 cows and you\n"
     ]
    }
   ],
>>>>>>> recover-day2
   "source": [
    "# 2. Few-shot prompting\n",
    "print(\"Testing few-shot prompting...\")\n",
    "few_shot = generator(\n",
    "    \"\"\"Here are some math problems:\n",
    "\n",
    "Q: There are 10 apples and you eat 4. How many are left?\n",
    "A: 6\n",
    "\n",
    "Q: You have 8 pencils and lose 3. How many do you have?\n",
    "A: 5\n",
    "\n",
    "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
    "A:\"\"\", \n",
    "    max_length=100,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "print(\"\\nðŸ”¹ Few-shot response:\")\n",
    "print(few_shot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "53400c16",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 7,
   "id": "53400c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing chain-of-thought prompting...\n",
      "\n",
      "ðŸ”¹ Chain-of-thought response:\n",
      "Let's solve this step by step:\n",
      "\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "1. The farmer starts with 17 sheep\n",
      "2. All sheep EXCEPT 9 run away\n",
      "3. This means 9 sheep stayed\n",
      "Therefore, 9 sheep are left.\n",
      "\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all\n",
      "\n",
      "ðŸ”¹ Chain-of-thought response:\n",
      "Let's solve this step by step:\n",
      "\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "1. The farmer starts with 17 sheep\n",
      "2. All sheep EXCEPT 9 run away\n",
      "3. This means 9 sheep stayed\n",
      "Therefore, 9 sheep are left.\n",
      "\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
      "A: Let's think about this:\n",
      "Q: A farmer has 17 sheep and all\n"
     ]
    }
   ],
>>>>>>> recover-day2
   "source": [
    "# 3. Chain-of-thought prompting\n",
    "print(\"Testing chain-of-thought prompting...\")\n",
    "cot = generator(\n",
    "    \"\"\"Let's solve this step by step:\n",
    "\n",
    "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
    "A: Let's think about this:\n",
    "1. The farmer starts with 17 sheep\n",
    "2. All sheep EXCEPT 9 run away\n",
    "3. This means 9 sheep stayed\n",
    "Therefore, 9 sheep are left.\n",
    "\n",
    "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
    "A:\"\"\",\n",
    "    max_length=150,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "print(\"\\nðŸ”¹ Chain-of-thought response:\")\n",
    "print(cot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10783d1a",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "We tested three different prompting techniques:\n",
    "1. Zero-shot: Just ask the question directly\n",
    "2. Few-shot: Show examples first, then ask\n",
    "3. Chain-of-thought: Guide the model through steps\n",
    "\n",
    "The correct answer is 9 sheep. Compare how each method performed!"
   ]
  }
 ],
 "metadata": {
<<<<<<< HEAD
  "language_info": {
   "name": "python"
=======
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
>>>>>>> recover-day2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
