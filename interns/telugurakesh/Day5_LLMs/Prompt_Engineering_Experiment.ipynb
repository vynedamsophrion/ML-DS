{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7260dba",
   "metadata": {},
   "source": [
    "# Simple Prompt Engineering Examples\n",
    "\n",
    "This notebook demonstrates three prompting techniques using a simple math problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the model\n",
    "print(\"Loading model...\")\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fae57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our test question\n",
    "question = \"A farmer has 17 sheep and all but 9 run away. How many sheep are left?\"\n",
    "print(f\"We will test this question: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Zero-shot prompting\n",
    "print(\"Testing zero-shot prompting...\")\n",
    "zero_shot = generator(\n",
    "    f\"Question: {question}\\nAnswer:\", \n",
    "    max_length=50, \n",
    "    num_return_sequences=1\n",
    ")\n",
    "print(\"\\nðŸ”¹ Zero-shot response:\")\n",
    "print(zero_shot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa3472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Few-shot prompting\n",
    "print(\"Testing few-shot prompting...\")\n",
    "few_shot = generator(\n",
    "    \"\"\"Here are some math problems:\n",
    "\n",
    "Q: There are 10 apples and you eat 4. How many are left?\n",
    "A: 6\n",
    "\n",
    "Q: You have 8 pencils and lose 3. How many do you have?\n",
    "A: 5\n",
    "\n",
    "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
    "A:\"\"\", \n",
    "    max_length=100,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "print(\"\\nðŸ”¹ Few-shot response:\")\n",
    "print(few_shot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53400c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Chain-of-thought prompting\n",
    "print(\"Testing chain-of-thought prompting...\")\n",
    "cot = generator(\n",
    "    \"\"\"Let's solve this step by step:\n",
    "\n",
    "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
    "A: Let's think about this:\n",
    "1. The farmer starts with 17 sheep\n",
    "2. All sheep EXCEPT 9 run away\n",
    "3. This means 9 sheep stayed\n",
    "Therefore, 9 sheep are left.\n",
    "\n",
    "Q: A farmer has 17 sheep and all but 9 run away. How many sheep are left?\n",
    "A:\"\"\",\n",
    "    max_length=150,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "print(\"\\nðŸ”¹ Chain-of-thought response:\")\n",
    "print(cot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10783d1a",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "We tested three different prompting techniques:\n",
    "1. Zero-shot: Just ask the question directly\n",
    "2. Few-shot: Show examples first, then ask\n",
    "3. Chain-of-thought: Guide the model through steps\n",
    "\n",
    "The correct answer is 9 sheep. Compare how each method performed!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
